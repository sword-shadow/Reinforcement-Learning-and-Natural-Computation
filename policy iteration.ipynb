{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c281c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58be5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP:\n",
    "    def __init__(self):\n",
    "        # state\n",
    "        self.v = np.zeros((21, 21))\n",
    "        # policy\n",
    "        self.pi = np.zeros((21, 21))\n",
    "        # poisson prob\n",
    "        self.prob_A = np.zeros((21, 21))\n",
    "        self.prob_B = np.zeros((21, 21))\n",
    "        for i in range(21):\n",
    "            for j in range(21):\n",
    "                self.prob_A[i, j] = self._poisson_calculator(i, 3) * self._poisson_calculator(j, 3)\n",
    "                self.prob_B[i, j] = self._poisson_calculator(i, 4) * self._poisson_calculator(j, 2)\n",
    "        # joint prob: p(s',r|s,a)\n",
    "        self.P = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    def _poisson_calculator(n, Lambda):\n",
    "        return Lambda ** n / np.math.factorial(n) * np.exp(-Lambda)\n",
    "        \n",
    "    def prob_cal(self):\n",
    "        \"\"\"\n",
    "        process: \n",
    "            S_T -> move car -> rent car -> return car -> S_(T+1)\n",
    "        function: \n",
    "            calculate the sum of prob\n",
    "        save / output:\n",
    "            p(s',r|s,a) -> P(S_A, S_B, action): dict{((S_A_next, S_B_next, reward)): joint prob}\n",
    "        \"\"\"\n",
    "        \n",
    "        start = time.time()\n",
    "        print(\"Prob calculation...\")\n",
    "        for state_A in range(21):  # loop the state\n",
    "            print(\"State \" + str(state_A))\n",
    "            for state_B in range(21): \n",
    "                for action in range(-5, 6):\n",
    "                    temp = {}\n",
    "                    if action <= state_A and -action <= state_B:\n",
    "                        for rent_A in range(21): # loop lend and return at day\n",
    "                            for rent_B in range(21):\n",
    "                                for return_A in range(21):\n",
    "                                    for return_B in range(21): # loop action at night  \n",
    "                                        state_A_next = min(20, state_A - min(rent_A,\n",
    "                                                                             state_A - action) + return_A - action)\n",
    "                                        state_B_next = min(20, state_B - min(rent_B,\n",
    "                                                                             state_B + action) + return_B + action)\n",
    "                                        reward = 10 * min(rent_A, state_A - action) + \\\n",
    "                                                 10 * min(rent_B, state_B + action) - \\\n",
    "                                                 abs(action) * 2\n",
    "                                        temp[((state_A_next, state_B_next),reward)] = temp.get(\n",
    "                                            ((state_A_next, state_B_next),reward), 0)\n",
    "                                        temp[((state_A_next, state_B_next),reward)] += \\\n",
    "                                            self.prob_A[rent_A, return_A] * self.prob_B[rent_B, return_B]\n",
    "                        self.P[(state_A, state_B), action] = temp\n",
    "        end = time.time()\n",
    "        print(f\"cost {round(end - start, 2)} s\")\n",
    "        \n",
    "    def policy_eval(self, epsilon=0.1):\n",
    "        print(\"Policy evaluation...\")\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            Delta = 0\n",
    "            for state_A in range(21):\n",
    "                for state_B in range(21):\n",
    "                    action = self.pi[state_A, state_B]\n",
    "                    p = self.P[(state_A, state_B), action]\n",
    "                    temp = 0\n",
    "                    for keys, values in p.items():\n",
    "                        (states, reward) = keys\n",
    "                        possibility = values\n",
    "                        temp += (reward + 0.9 * self.v[states]) * possibility\n",
    "                    old_value = self.v[state_A, state_B]\n",
    "                    self.v[state_A, state_B] = temp\n",
    "                    Delta = max(Delta, abs(self.v[state_A, state_B] - old_value))\n",
    "            if Delta < epsilon:\n",
    "                break\n",
    "        end = time.time()\n",
    "        print(f\"cost {round(end - start, 2)} s\")\n",
    "        \n",
    "    def policy_improvement(self):\n",
    "        start = time.time()\n",
    "        print(\"Policy improvement...\")\n",
    "        policy_stable = True\n",
    "        for state_A in range(21):\n",
    "            for state_B in range(21):\n",
    "                action_value = np.zeros(11)\n",
    "                for action in range(-5, 6):\n",
    "                    if action <= state_A and -action <= state_B:\n",
    "                        p = self.P[(state_A, state_B), action]\n",
    "                        for keys, values in p.items():\n",
    "                            (states, reward) = keys\n",
    "                            possibility = values\n",
    "                            action_value[action + 5] += (reward + 0.9 * self.v[states]) * possibility\n",
    "                    else:\n",
    "                        action_value[action + 5] = -1e9\n",
    "                old_action = self.pi[state_A, state_B]\n",
    "                self.pi[state_A, state_B] = np.argmax(action_value) - 5\n",
    "                if self.pi[state_A, state_B] != old_action:\n",
    "                    policy_stable = False\n",
    "        end = time.time()\n",
    "        print(f\"cost {round(end - start, 2)} s\")\n",
    "        return policy_stable\n",
    "    \n",
    "    def train(self):\n",
    "        self.prob_cal()\n",
    "        for q in range(5):\n",
    "            print(f\"***** Big loop {q + 1} *****\")\n",
    "            self.policy_eval()\n",
    "            if self.policy_improvement():\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225be91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob calculation...\n",
      "State 0\n",
      "State 1\n",
      "State 2\n",
      "State 3\n",
      "State 4\n",
      "State 5\n",
      "State 6\n",
      "State 7\n",
      "State 8\n",
      "State 9\n",
      "State 10\n",
      "State 11\n",
      "State 12\n",
      "State 13\n",
      "State 14\n",
      "State 15\n",
      "State 16\n",
      "State 17\n",
      "State 18\n",
      "State 19\n",
      "State 20\n",
      "cost 1012.77 s\n",
      "***** Big loop 1 *****\n",
      "Policy evaluation...\n",
      "cost 27.25 s\n",
      "Policy improvement...\n",
      "cost 10.99 s\n",
      "***** Big loop 2 *****\n",
      "Policy evaluation...\n",
      "cost 14.01 s\n",
      "Policy improvement...\n",
      "cost 10.85 s\n",
      "***** Big loop 3 *****\n",
      "Policy evaluation...\n",
      "cost 9.74 s\n",
      "Policy improvement...\n",
      "cost 10.87 s\n",
      "***** Big loop 4 *****\n",
      "Policy evaluation...\n",
      "cost 3.0 s\n",
      "Policy improvement...\n",
      "cost 10.69 s\n",
      "***** Big loop 5 *****\n",
      "Policy evaluation...\n",
      "cost 0.87 s\n",
      "Policy improvement...\n",
      "cost 10.71 s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dp = DP()\n",
    "    dp.train()\n",
    "    \n",
    "    # plt.imshow(dp.pi, cmap=plt.cm.get_cmap('gray', 9), origin='lower')\n",
    "    # plt.yticks(np.arange(0,21,5))\n",
    "    # plt.colorbar()\n",
    "    \n",
    "    # plt.imshow(dp.v, cmap='gray', origin='lower')\n",
    "    # plt.yticks(np.arange(0,21,5))\n",
    "    # plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
